{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fwumious Wabbit demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " to learn more about Fwumious Wabbit go [here]( https://github.com/outbrain/fwumious_wabbit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wabbit showdown: Fwumious vs. Vowpal\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this benchmark demonstrates the potential gains from using Fwumious Wabbit as a drop-in replacement for Vowpal Wabbit.\n",
    "\n",
    "depending on your dataset and system, you can get a significant performance boost by using FW.\n",
    "\n",
    "not only is it faster per task, it's also more efficient in CPU utilization - which means we can run more concurrent training tasks. this improves our AutoML infrastructure's throughput measured in model evaluations per hour.\n",
    "\n",
    "\n",
    "having a better througput lets our data scientists get more work done - resulting in better models.\n",
    "\n",
    "you can read about the speedups [here]( https://github.com/outbrain/fwumious_wabbit/blob/master/SPEED.md)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### system information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================== CPU Info ========================================\r\n",
      "Physical cores: 4\r\n",
      "Total cores: 8\r\n",
      "Current Frequency: 2900.00Mhz\r\n",
      "======================================== System Information ========================================\r\n",
      "System: Darwin\r\n",
      "Release: 19.6.0\r\n",
      "Version: Darwin Kernel Version 19.6.0: Thu Jun 18 20:49:00 PDT 2020; root:xnu-6153.141.1~1/RELEASE_X86_64\r\n",
      "Machine: x86_64\r\n",
      "Processor: i386\r\n"
     ]
    }
   ],
   "source": [
    "!python print_system_info.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### the task: Eat-rate prediction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We generate a dataset containing 5,000,000 records documenting animal-food encounters.\n",
    "\n",
    "each record is made of animal, food and outcome - either the animal eats the food (1) or it doesn't eat it (-1)\n",
    "\n",
    "Namespace A will be Animal, and B will be Food.\n",
    "\n",
    "Each animal has its latent type - Herbivore or Carnivore.\n",
    "\n",
    "Each food has its latent type - Plant or Meat.\n",
    "\n",
    "We use feature names like \"Herbivore-13\" and \"Plant-55\". for vw and fw, these are just strings. But they give us humans a hint as to the expected outcome (herbivores like plants, and carnivores like meat...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### simple logistic regression showdown\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### genereate dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python cleanup.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python generate.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "review the first 10 lines of the generated training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1 |A Herbivore-5 |B Meat-0\r\n",
      "-1 |A Carnivore-3 |B Plant-0\r\n",
      "1 |A Carnivore-0 |B Meat-2\r\n",
      "1 |A Carnivore-3 |B Meat-1\r\n",
      "1 |A Herbivore-0 |B Plant-2\r\n",
      "1 |A Herbivore-0 |B Plant-0\r\n",
      "1 |A Herbivore-4 |B Plant-1\r\n",
      "1 |A Herbivore-1 |B Plant-3\r\n",
      "-1 |A Herbivore-3 |B Meat-2\r\n",
      "-1 |A Herbivore-0 |B Meat-3\r\n"
     ]
    }
   ],
   "source": [
    "!head -n 10 train.vw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gzip train.vw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### measure vw training time - not reading from cache (cache file is created)\n",
    "\n",
    "*note that in order for the model to learn successfully - we use feature interactions. if we replace \"--interactions AB\" with \"--keep A --keep B\" the model won't improve with training.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python clean_caches.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.30s user 6.54s system 162% cpu 7.919 total\r\n"
     ]
    }
   ],
   "source": [
    "!(time vw --data train.vw.gz -l 0.1 -b 25 -c --adaptive --sgd --loss_function logistic --link logistic --power_t 0.0 --l2 0.0 --hash all --final_regressor vw_model --save_resume --interactions AB) 2>&1 >/dev/null  | tail -n 1 | awk -F\" \" '{ print $13\" \"$14\" \"$15\" \"$16\" \"$17\" \"$18\" \"$19\" \"$20}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### measure fw training time - not reading from cache (cache file is created)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.77s user 0.20s system 93% cpu 1.030 total\r\n"
     ]
    }
   ],
   "source": [
    "!(time ./fw --data train.vw.gz -l 0.1 -b 25 -c --adaptive --fastmath --sgd --loss_function logistic --link logistic --power_t 0.0 --l2 0.0 --hash all --final_regressor fw_model --save_resume --interactions AB) 2>&1 >/dev/null  | tail -n 1 | awk -F\" \" '{ print $13\" \"$14\" \"$15\" \"$16\" \"$17\" \"$18\" \"$19\" \"$20}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### now repeat the training for vw and fw - this time using the cache:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.12s user 6.83s system 164% cpu 7.863 total\r\n"
     ]
    }
   ],
   "source": [
    "!(time vw --data train.vw.gz -l 0.1 -b 25 -c --adaptive --sgd --loss_function logistic --link logistic --power_t 0.0 --l2 0.0 --hash all --interactions AB) 2>&1 >/dev/null  | tail -n 1 | awk -F\" \" '{ print $13\" \"$14\" \"$15\" \"$16\" \"$17\" \"$18\" \"$19\" \"$20}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user 0.07s system 99% cpu 0.844 total \r\n"
     ]
    }
   ],
   "source": [
    "!(time ./fw --data train.vw.gz -l 0.1 -b 25 -c --adaptive --sgd --loss_function logistic --link logistic --power_t 0.0 --l2 0.0 --hash all --interactions AB) 2>&1 >/dev/null  | tail -n 1 | awk -F\" \" '{ print $13\" \"$14\" \"$15\" \"$16\" \"$17\" \"$18\" \"$19\" \"$20}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### predict using the trained model, and write predictions to output file (not using cache):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reading from easy.vw - a file with 5M records.\n",
    "\n",
    "first using vw, then using fw:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user 27.96s system 151% cpu 29.323 total \r\n"
     ]
    }
   ],
   "source": [
    "!(time vw --data easy.vw -t -b 25 -p vw_preds.out --link logistic --initial_regressor vw_model --hash all --interactions AB) 2>&1 >/dev/null  | tail -n 1 | awk -F\" \" '{ print $13\" \"$14\" \"$15\" \"$16\" \"$17\" \"$18\" \"$19\" \"$20}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user 0.20s system 98% cpu 2.022 total \r\n"
     ]
    }
   ],
   "source": [
    "!(time ./fw --data easy.vw --sgd --adaptive -t -b 25 -p fw_preds.out --initial_regressor fw_model --link logistic --hash all --interactions AB) 2>&1 >/dev/null  | tail -n 1 | awk -F\" \" '{ print $14\" \"$15\" \"$16\" \"$17\" \"$18\" \"$19\" \"$20\" \"$21}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### evaluate predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
